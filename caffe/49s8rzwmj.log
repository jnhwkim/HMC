I0112 15:16:53.251449 1994072832 caffe.cpp:99] Use GPU with device ID 0
I0112 15:16:53.401443 1994072832 caffe.cpp:107] Starting Optimization
I0112 15:16:53.401470 1994072832 solver.cpp:32] Initializing solver from parameters: 
test_iter: 100
test_interval: 100000
base_lr: 0.01
display: 10000
max_iter: 10000000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 100000
snapshot_prefix: ".49s1rzwmj"
solver_mode: GPU
random_seed: 1710
net_param {
  name: "LeNet"
  layers {
    top: "data"
    top: "label"
    name: "mnist"
    type: DATA
    data_param {
      source: "49s1rzmj_tr_ldb"
      batch_size: 60
      backend: LEVELDB
    }
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.00390625
    }
  }
  layers {
    top: "data"
    top: "label"
    name: "mnist"
    type: DATA
    data_param {
      source: "49s1rzmj_te_ldb"
      batch_size: 100
      backend: LEVELDB
    }
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.00390625
    }
  }
  layers {
    bottom: "data"
    top: "ip1"
    name: "ip1"
    type: INNER_PRODUCT
    blobs_lr: 1
    blobs_lr: 2
    inner_product_param {
      num_output: 800
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    bottom: "ip1"
    top: "ip1"
    name: "relu1"
    type: RELU
  }
  layers {
    bottom: "ip1"
    top: "ip2"
    name: "ip2"
    type: INNER_PRODUCT
    blobs_lr: 1
    blobs_lr: 2
    inner_product_param {
      num_output: 500
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    bottom: "ip2"
    top: "ip2"
    name: "relu2"
    type: RELU
  }
  layers {
    bottom: "ip2"
    top: "ip3"
    name: "ip3"
    type: INNER_PRODUCT
    blobs_lr: 1
    blobs_lr: 2
    inner_product_param {
      num_output: 10
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    bottom: "ip3"
    bottom: "label"
    top: "accuracy"
    name: "accuracy"
    type: ACCURACY
  }
  layers {
    bottom: "ip3"
    bottom: "label"
    top: "loss"
    name: "loss"
    type: SOFTMAX_LOSS
  }
}
test_state {
  stage: "test-on-test-set"
}
I0112 15:16:53.401865 1994072832 solver.cpp:63] Creating training net specified in net_param.
I0112 15:16:53.401962 1994072832 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0112 15:16:53.401979 1994072832 net.cpp:39] Initializing net from parameters: 
name: "LeNet"
layers {
  top: "data"
  top: "label"
  name: "mnist"
  type: DATA
  data_param {
    source: "49s1rzmj_tr_ldb"
    batch_size: 60
    backend: LEVELDB
  }
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
}
layers {
  bottom: "data"
  top: "ip1"
  name: "ip1"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 800
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip1"
  top: "ip1"
  name: "relu1"
  type: RELU
}
layers {
  bottom: "ip1"
  top: "ip2"
  name: "ip2"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip2"
  top: "ip2"
  name: "relu2"
  type: RELU
}
layers {
  bottom: "ip2"
  top: "ip3"
  name: "ip3"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: ACCURACY
}
layers {
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I0112 15:16:53.402264 1994072832 net.cpp:67] Creating Layer mnist
I0112 15:16:53.402272 1994072832 net.cpp:356] mnist -> data
I0112 15:16:53.402288 1994072832 net.cpp:356] mnist -> label
I0112 15:16:53.402295 1994072832 net.cpp:96] Setting up mnist
I0112 15:16:53.402349 1994072832 data_layer.cpp:45] Opening leveldb 49s1rzmj_tr_ldb
I0112 15:16:53.443153 1994072832 data_layer.cpp:128] output data size: 60,1,1,245
I0112 15:16:53.443318 1994072832 net.cpp:103] Top shape: 60 1 1 245 (14700)
I0112 15:16:53.443325 1994072832 net.cpp:103] Top shape: 60 1 1 1 (60)
I0112 15:16:53.443339 1994072832 net.cpp:67] Creating Layer label_mnist_1_split
I0112 15:16:53.443344 1994072832 net.cpp:394] label_mnist_1_split <- label
I0112 15:16:53.443352 1994072832 net.cpp:356] label_mnist_1_split -> label_mnist_1_split_0
I0112 15:16:53.443363 1994072832 net.cpp:356] label_mnist_1_split -> label_mnist_1_split_1
I0112 15:16:53.443369 1994072832 net.cpp:96] Setting up label_mnist_1_split
I0112 15:16:53.443374 1994072832 net.cpp:103] Top shape: 60 1 1 1 (60)
I0112 15:16:53.443377 1994072832 net.cpp:103] Top shape: 60 1 1 1 (60)
I0112 15:16:53.443382 1994072832 net.cpp:67] Creating Layer ip1
I0112 15:16:53.443387 1994072832 net.cpp:394] ip1 <- data
I0112 15:16:53.443390 1994072832 net.cpp:356] ip1 -> ip1
I0112 15:16:53.443397 1994072832 net.cpp:96] Setting up ip1
I0112 15:16:53.444736 1994072832 net.cpp:103] Top shape: 60 800 1 1 (48000)
I0112 15:16:53.444752 1994072832 net.cpp:67] Creating Layer relu1
I0112 15:16:53.444756 1994072832 net.cpp:394] relu1 <- ip1
I0112 15:16:53.444759 1994072832 net.cpp:345] relu1 -> ip1 (in-place)
I0112 15:16:53.444763 1994072832 net.cpp:96] Setting up relu1
I0112 15:16:53.444767 1994072832 net.cpp:103] Top shape: 60 800 1 1 (48000)
I0112 15:16:53.444772 1994072832 net.cpp:67] Creating Layer ip2
I0112 15:16:53.444774 1994072832 net.cpp:394] ip2 <- ip1
I0112 15:16:53.444778 1994072832 net.cpp:356] ip2 -> ip2
I0112 15:16:53.444783 1994072832 net.cpp:96] Setting up ip2
I0112 15:16:53.447542 1994072832 net.cpp:103] Top shape: 60 500 1 1 (30000)
I0112 15:16:53.447556 1994072832 net.cpp:67] Creating Layer relu2
I0112 15:16:53.447558 1994072832 net.cpp:394] relu2 <- ip2
I0112 15:16:53.447562 1994072832 net.cpp:345] relu2 -> ip2 (in-place)
I0112 15:16:53.447567 1994072832 net.cpp:96] Setting up relu2
I0112 15:16:53.447571 1994072832 net.cpp:103] Top shape: 60 500 1 1 (30000)
I0112 15:16:53.447578 1994072832 net.cpp:67] Creating Layer ip3
I0112 15:16:53.447582 1994072832 net.cpp:394] ip3 <- ip2
I0112 15:16:53.447585 1994072832 net.cpp:356] ip3 -> ip3
I0112 15:16:53.447590 1994072832 net.cpp:96] Setting up ip3
I0112 15:16:53.447628 1994072832 net.cpp:103] Top shape: 60 10 1 1 (600)
I0112 15:16:53.447633 1994072832 net.cpp:67] Creating Layer ip3_ip3_0_split
I0112 15:16:53.447636 1994072832 net.cpp:394] ip3_ip3_0_split <- ip3
I0112 15:16:53.447641 1994072832 net.cpp:356] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0112 15:16:53.447646 1994072832 net.cpp:356] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0112 15:16:53.447651 1994072832 net.cpp:96] Setting up ip3_ip3_0_split
I0112 15:16:53.447655 1994072832 net.cpp:103] Top shape: 60 10 1 1 (600)
I0112 15:16:53.447659 1994072832 net.cpp:103] Top shape: 60 10 1 1 (600)
I0112 15:16:53.447664 1994072832 net.cpp:67] Creating Layer accuracy
I0112 15:16:53.447666 1994072832 net.cpp:394] accuracy <- ip3_ip3_0_split_0
I0112 15:16:53.447669 1994072832 net.cpp:394] accuracy <- label_mnist_1_split_0
I0112 15:16:53.447675 1994072832 net.cpp:356] accuracy -> accuracy
I0112 15:16:53.447680 1994072832 net.cpp:96] Setting up accuracy
I0112 15:16:53.447685 1994072832 net.cpp:103] Top shape: 1 1 1 1 (1)
I0112 15:16:53.447691 1994072832 net.cpp:67] Creating Layer loss
I0112 15:16:53.447695 1994072832 net.cpp:394] loss <- ip3_ip3_0_split_1
I0112 15:16:53.447698 1994072832 net.cpp:394] loss <- label_mnist_1_split_1
I0112 15:16:53.447702 1994072832 net.cpp:356] loss -> loss
I0112 15:16:53.447707 1994072832 net.cpp:96] Setting up loss
I0112 15:16:53.447717 1994072832 net.cpp:103] Top shape: 1 1 1 1 (1)
I0112 15:16:53.447721 1994072832 net.cpp:109]     with loss weight 1
I0112 15:16:53.447731 1994072832 net.cpp:170] loss needs backward computation.
I0112 15:16:53.447733 1994072832 net.cpp:172] accuracy does not need backward computation.
I0112 15:16:53.447762 1994072832 net.cpp:170] ip3_ip3_0_split needs backward computation.
I0112 15:16:53.447765 1994072832 net.cpp:170] ip3 needs backward computation.
I0112 15:16:53.447768 1994072832 net.cpp:170] relu2 needs backward computation.
I0112 15:16:53.447772 1994072832 net.cpp:170] ip2 needs backward computation.
I0112 15:16:53.447774 1994072832 net.cpp:170] relu1 needs backward computation.
I0112 15:16:53.447777 1994072832 net.cpp:170] ip1 needs backward computation.
I0112 15:16:53.447779 1994072832 net.cpp:172] label_mnist_1_split does not need backward computation.
I0112 15:16:53.447783 1994072832 net.cpp:172] mnist does not need backward computation.
I0112 15:16:53.447787 1994072832 net.cpp:208] This network produces output accuracy
I0112 15:16:53.447790 1994072832 net.cpp:208] This network produces output loss
I0112 15:16:53.447798 1994072832 net.cpp:467] Collecting Learning Rate and Weight Decay.
I0112 15:16:53.447805 1994072832 net.cpp:219] Network initialization done.
I0112 15:16:53.447808 1994072832 net.cpp:220] Memory required for data: 690728
I0112 15:16:53.447865 1994072832 solver.cpp:151] Creating test net (#0) specified by net_param
I0112 15:16:53.447880 1994072832 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0112 15:16:53.447890 1994072832 net.cpp:39] Initializing net from parameters: 
name: "LeNet"
layers {
  top: "data"
  top: "label"
  name: "mnist"
  type: DATA
  data_param {
    source: "49s1rzmj_te_ldb"
    batch_size: 100
    backend: LEVELDB
  }
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
}
layers {
  bottom: "data"
  top: "ip1"
  name: "ip1"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 800
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip1"
  top: "ip1"
  name: "relu1"
  type: RELU
}
layers {
  bottom: "ip1"
  top: "ip2"
  name: "ip2"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip2"
  top: "ip2"
  name: "relu2"
  type: RELU
}
layers {
  bottom: "ip2"
  top: "ip3"
  name: "ip3"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layers {
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: ACCURACY
}
layers {
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TEST
  stage: "test-on-test-set"
}
I0112 15:16:53.448127 1994072832 net.cpp:67] Creating Layer mnist
I0112 15:16:53.448133 1994072832 net.cpp:356] mnist -> data
I0112 15:16:53.448140 1994072832 net.cpp:356] mnist -> label
I0112 15:16:53.448146 1994072832 net.cpp:96] Setting up mnist
I0112 15:16:53.448150 1994072832 data_layer.cpp:45] Opening leveldb 49s1rzmj_te_ldb
I0112 15:16:53.517822 1994072832 data_layer.cpp:128] output data size: 100,1,1,245
I0112 15:16:53.517882 1994072832 net.cpp:103] Top shape: 100 1 1 245 (24500)
I0112 15:16:53.517889 1994072832 net.cpp:103] Top shape: 100 1 1 1 (100)
I0112 15:16:53.517900 1994072832 net.cpp:67] Creating Layer label_mnist_1_split
I0112 15:16:53.517904 1994072832 net.cpp:394] label_mnist_1_split <- label
I0112 15:16:53.517910 1994072832 net.cpp:356] label_mnist_1_split -> label_mnist_1_split_0
I0112 15:16:53.517918 1994072832 net.cpp:356] label_mnist_1_split -> label_mnist_1_split_1
I0112 15:16:53.517948 1994072832 net.cpp:96] Setting up label_mnist_1_split
I0112 15:16:53.517956 1994072832 net.cpp:103] Top shape: 100 1 1 1 (100)
I0112 15:16:53.517959 1994072832 net.cpp:103] Top shape: 100 1 1 1 (100)
I0112 15:16:53.517966 1994072832 net.cpp:67] Creating Layer ip1
I0112 15:16:53.517969 1994072832 net.cpp:394] ip1 <- data
I0112 15:16:53.517976 1994072832 net.cpp:356] ip1 -> ip1
I0112 15:16:53.517983 1994072832 net.cpp:96] Setting up ip1
I0112 15:16:53.519086 1994072832 net.cpp:103] Top shape: 100 800 1 1 (80000)
I0112 15:16:53.519098 1994072832 net.cpp:67] Creating Layer relu1
I0112 15:16:53.519103 1994072832 net.cpp:394] relu1 <- ip1
I0112 15:16:53.519106 1994072832 net.cpp:345] relu1 -> ip1 (in-place)
I0112 15:16:53.519111 1994072832 net.cpp:96] Setting up relu1
I0112 15:16:53.519114 1994072832 net.cpp:103] Top shape: 100 800 1 1 (80000)
I0112 15:16:53.519129 1994072832 net.cpp:67] Creating Layer ip2
I0112 15:16:53.519134 1994072832 net.cpp:394] ip2 <- ip1
I0112 15:16:53.519139 1994072832 net.cpp:356] ip2 -> ip2
I0112 15:16:53.519143 1994072832 net.cpp:96] Setting up ip2
I0112 15:16:53.522048 1994072832 net.cpp:103] Top shape: 100 500 1 1 (50000)
I0112 15:16:53.522073 1994072832 net.cpp:67] Creating Layer relu2
I0112 15:16:53.522078 1994072832 net.cpp:394] relu2 <- ip2
I0112 15:16:53.522083 1994072832 net.cpp:345] relu2 -> ip2 (in-place)
I0112 15:16:53.522089 1994072832 net.cpp:96] Setting up relu2
I0112 15:16:53.522092 1994072832 net.cpp:103] Top shape: 100 500 1 1 (50000)
I0112 15:16:53.522099 1994072832 net.cpp:67] Creating Layer ip3
I0112 15:16:53.522101 1994072832 net.cpp:394] ip3 <- ip2
I0112 15:16:53.522110 1994072832 net.cpp:356] ip3 -> ip3
I0112 15:16:53.522119 1994072832 net.cpp:96] Setting up ip3
I0112 15:16:53.522176 1994072832 net.cpp:103] Top shape: 100 10 1 1 (1000)
I0112 15:16:53.522193 1994072832 net.cpp:67] Creating Layer ip3_ip3_0_split
I0112 15:16:53.522197 1994072832 net.cpp:394] ip3_ip3_0_split <- ip3
I0112 15:16:53.522203 1994072832 net.cpp:356] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0112 15:16:53.522209 1994072832 net.cpp:356] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0112 15:16:53.522215 1994072832 net.cpp:96] Setting up ip3_ip3_0_split
I0112 15:16:53.522220 1994072832 net.cpp:103] Top shape: 100 10 1 1 (1000)
I0112 15:16:53.522224 1994072832 net.cpp:103] Top shape: 100 10 1 1 (1000)
I0112 15:16:53.522233 1994072832 net.cpp:67] Creating Layer accuracy
I0112 15:16:53.522238 1994072832 net.cpp:394] accuracy <- ip3_ip3_0_split_0
I0112 15:16:53.522263 1994072832 net.cpp:394] accuracy <- label_mnist_1_split_0
I0112 15:16:53.522269 1994072832 net.cpp:356] accuracy -> accuracy
I0112 15:16:53.522274 1994072832 net.cpp:96] Setting up accuracy
I0112 15:16:53.522277 1994072832 net.cpp:103] Top shape: 1 1 1 1 (1)
I0112 15:16:53.522284 1994072832 net.cpp:67] Creating Layer loss
I0112 15:16:53.522286 1994072832 net.cpp:394] loss <- ip3_ip3_0_split_1
I0112 15:16:53.522289 1994072832 net.cpp:394] loss <- label_mnist_1_split_1
I0112 15:16:53.522294 1994072832 net.cpp:356] loss -> loss
I0112 15:16:53.522299 1994072832 net.cpp:96] Setting up loss
I0112 15:16:53.522305 1994072832 net.cpp:103] Top shape: 1 1 1 1 (1)
I0112 15:16:53.522320 1994072832 net.cpp:109]     with loss weight 1
I0112 15:16:53.522330 1994072832 net.cpp:170] loss needs backward computation.
I0112 15:16:53.522333 1994072832 net.cpp:172] accuracy does not need backward computation.
I0112 15:16:53.522336 1994072832 net.cpp:170] ip3_ip3_0_split needs backward computation.
I0112 15:16:53.522339 1994072832 net.cpp:170] ip3 needs backward computation.
I0112 15:16:53.522342 1994072832 net.cpp:170] relu2 needs backward computation.
I0112 15:16:53.522346 1994072832 net.cpp:170] ip2 needs backward computation.
I0112 15:16:53.522348 1994072832 net.cpp:170] relu1 needs backward computation.
I0112 15:16:53.522351 1994072832 net.cpp:170] ip1 needs backward computation.
I0112 15:16:53.522356 1994072832 net.cpp:172] label_mnist_1_split does not need backward computation.
I0112 15:16:53.522359 1994072832 net.cpp:172] mnist does not need backward computation.
I0112 15:16:53.522361 1994072832 net.cpp:208] This network produces output accuracy
I0112 15:16:53.522368 1994072832 net.cpp:208] This network produces output loss
I0112 15:16:53.522377 1994072832 net.cpp:467] Collecting Learning Rate and Weight Decay.
I0112 15:16:53.522392 1994072832 net.cpp:219] Network initialization done.
I0112 15:16:53.522403 1994072832 net.cpp:220] Memory required for data: 1151208
I0112 15:16:53.522565 1994072832 solver.cpp:41] Solver scaffolding done.
I0112 15:16:53.522574 1994072832 solver.cpp:160] Solving LeNet
I0112 15:16:53.522593 1994072832 solver.cpp:247] Iteration 0, Testing net (#0)
I0112 15:16:53.677460 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.0974
I0112 15:16:53.677489 1994072832 solver.cpp:298]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I0112 15:16:53.685842 1994072832 solver.cpp:191] Iteration 0, loss = 2.30261
I0112 15:16:53.685868 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.0833333
I0112 15:16:53.685874 1994072832 solver.cpp:206]     Train net output #1: loss = 2.30261 (* 1 = 2.30261 loss)
I0112 15:16:53.685883 1994072832 solver.cpp:403] Iteration 0, lr = 0.01
I0112 15:17:12.556229 1994072832 solver.cpp:191] Iteration 10000, loss = 1.43064
I0112 15:17:12.556255 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.483333
I0112 15:17:12.556262 1994072832 solver.cpp:206]     Train net output #1: loss = 1.43064 (* 1 = 1.43064 loss)
I0112 15:17:12.556267 1994072832 solver.cpp:403] Iteration 10000, lr = 0.00594604
I0112 15:17:30.896044 1994072832 solver.cpp:191] Iteration 20000, loss = 1.20954
I0112 15:17:30.896071 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.533333
I0112 15:17:30.896071 1994072832 solver.cpp:206]     Train net output #1: loss = 1.20954 (* 1 = 1.20954 loss)
I0112 15:17:30.896071 1994072832 solver.cpp:403] Iteration 20000, lr = 0.00438691
I0112 15:17:49.497602 1994072832 solver.cpp:191] Iteration 30000, loss = 1.00839
I0112 15:17:49.497629 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.6
I0112 15:17:49.497637 1994072832 solver.cpp:206]     Train net output #1: loss = 1.00839 (* 1 = 1.00839 loss)
I0112 15:17:49.497642 1994072832 solver.cpp:403] Iteration 30000, lr = 0.00353553
I0112 15:18:08.164265 1994072832 solver.cpp:191] Iteration 40000, loss = 0.900851
I0112 15:18:08.172297 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.7
I0112 15:18:08.172309 1994072832 solver.cpp:206]     Train net output #1: loss = 0.900851 (* 1 = 0.900851 loss)
I0112 15:18:08.172313 1994072832 solver.cpp:403] Iteration 40000, lr = 0.0029907
I0112 15:18:27.074437 1994072832 solver.cpp:191] Iteration 50000, loss = 0.887089
I0112 15:18:27.074461 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.666667
I0112 15:18:27.074468 1994072832 solver.cpp:206]     Train net output #1: loss = 0.887089 (* 1 = 0.887089 loss)
I0112 15:18:27.074473 1994072832 solver.cpp:403] Iteration 50000, lr = 0.00260847
I0112 15:18:45.977247 1994072832 solver.cpp:191] Iteration 60000, loss = 0.863759
I0112 15:18:45.977285 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.683333
I0112 15:18:45.977293 1994072832 solver.cpp:206]     Train net output #1: loss = 0.863759 (* 1 = 0.863759 loss)
I0112 15:18:45.977299 1994072832 solver.cpp:403] Iteration 60000, lr = 0.00232368
I0112 15:19:04.637547 1994072832 solver.cpp:191] Iteration 70000, loss = 0.822218
I0112 15:19:04.637573 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.683333
I0112 15:19:04.637579 1994072832 solver.cpp:206]     Train net output #1: loss = 0.822218 (* 1 = 0.822218 loss)
I0112 15:19:04.637584 1994072832 solver.cpp:403] Iteration 70000, lr = 0.00210224
I0112 15:19:23.099108 1994072832 solver.cpp:191] Iteration 80000, loss = 0.768496
I0112 15:19:23.099145 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.7
I0112 15:19:23.099153 1994072832 solver.cpp:206]     Train net output #1: loss = 0.768496 (* 1 = 0.768496 loss)
I0112 15:19:23.099191 1994072832 solver.cpp:403] Iteration 80000, lr = 0.0019245
I0112 15:19:41.558609 1994072832 solver.cpp:191] Iteration 90000, loss = 0.738402
I0112 15:19:41.558635 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.7
I0112 15:19:41.558642 1994072832 solver.cpp:206]     Train net output #1: loss = 0.738402 (* 1 = 0.738402 loss)
I0112 15:19:41.558647 1994072832 solver.cpp:403] Iteration 90000, lr = 0.00177828
I0112 15:19:59.972991 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_100000.caffemodel
I0112 15:19:59.996680 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_100000.solverstate
I0112 15:20:00.005661 1994072832 solver.cpp:247] Iteration 100000, Testing net (#0)
I0112 15:20:00.069864 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7134
I0112 15:20:00.069888 1994072832 solver.cpp:298]     Test net output #1: loss = 0.838497 (* 1 = 0.838497 loss)
I0112 15:20:00.070529 1994072832 solver.cpp:191] Iteration 100000, loss = 0.69557
I0112 15:20:00.070544 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.7
I0112 15:20:00.070551 1994072832 solver.cpp:206]     Train net output #1: loss = 0.69557 (* 1 = 0.69557 loss)
I0112 15:20:00.070557 1994072832 solver.cpp:403] Iteration 100000, lr = 0.0016556
I0112 15:20:18.488472 1994072832 solver.cpp:191] Iteration 110000, loss = 0.656542
I0112 15:20:18.488499 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.716667
I0112 15:20:18.488507 1994072832 solver.cpp:206]     Train net output #1: loss = 0.656542 (* 1 = 0.656542 loss)
I0112 15:20:18.488512 1994072832 solver.cpp:403] Iteration 110000, lr = 0.00155101
I0112 15:20:36.870924 1994072832 solver.cpp:191] Iteration 120000, loss = 0.622308
I0112 15:20:36.870962 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.733333
I0112 15:20:36.870970 1994072832 solver.cpp:206]     Train net output #1: loss = 0.622308 (* 1 = 0.622308 loss)
I0112 15:20:36.870976 1994072832 solver.cpp:403] Iteration 120000, lr = 0.00146064
I0112 15:20:55.247913 1994072832 solver.cpp:191] Iteration 130000, loss = 0.592837
I0112 15:20:55.247939 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.733333
I0112 15:20:55.247947 1994072832 solver.cpp:206]     Train net output #1: loss = 0.592837 (* 1 = 0.592837 loss)
I0112 15:20:55.247952 1994072832 solver.cpp:403] Iteration 130000, lr = 0.00138167
I0112 15:21:13.666012 1994072832 solver.cpp:191] Iteration 140000, loss = 0.559847
I0112 15:21:13.666049 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.75
I0112 15:21:13.666057 1994072832 solver.cpp:206]     Train net output #1: loss = 0.559847 (* 1 = 0.559847 loss)
I0112 15:21:13.666095 1994072832 solver.cpp:403] Iteration 140000, lr = 0.00131199
I0112 15:21:32.065603 1994072832 solver.cpp:191] Iteration 150000, loss = 0.545753
I0112 15:21:32.065626 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.733333
I0112 15:21:32.065634 1994072832 solver.cpp:206]     Train net output #1: loss = 0.545753 (* 1 = 0.545753 loss)
I0112 15:21:32.065641 1994072832 solver.cpp:403] Iteration 150000, lr = 0.00125
I0112 15:21:50.443800 1994072832 solver.cpp:191] Iteration 160000, loss = 0.524837
I0112 15:21:50.443838 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.8
I0112 15:21:50.443847 1994072832 solver.cpp:206]     Train net output #1: loss = 0.524837 (* 1 = 0.524837 loss)
I0112 15:21:50.443883 1994072832 solver.cpp:403] Iteration 160000, lr = 0.00119444
I0112 15:22:08.875074 1994072832 solver.cpp:191] Iteration 170000, loss = 0.501591
I0112 15:22:08.875100 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.8
I0112 15:22:08.875108 1994072832 solver.cpp:206]     Train net output #1: loss = 0.501591 (* 1 = 0.501591 loss)
I0112 15:22:08.875113 1994072832 solver.cpp:403] Iteration 170000, lr = 0.00114431
I0112 15:22:27.354473 1994072832 solver.cpp:191] Iteration 180000, loss = 0.483027
I0112 15:22:27.354512 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.816667
I0112 15:22:27.354524 1994072832 solver.cpp:206]     Train net output #1: loss = 0.483027 (* 1 = 0.483027 loss)
I0112 15:22:27.354529 1994072832 solver.cpp:403] Iteration 180000, lr = 0.00109884
I0112 15:22:45.753618 1994072832 solver.cpp:191] Iteration 190000, loss = 0.459482
I0112 15:22:45.753643 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.816667
I0112 15:22:45.753651 1994072832 solver.cpp:206]     Train net output #1: loss = 0.459482 (* 1 = 0.459482 loss)
I0112 15:22:45.753655 1994072832 solver.cpp:403] Iteration 190000, lr = 0.00105737
I0112 15:23:04.129899 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_200000.caffemodel
I0112 15:23:04.150650 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_200000.solverstate
I0112 15:23:04.159322 1994072832 solver.cpp:247] Iteration 200000, Testing net (#0)
I0112 15:23:04.222877 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7412
I0112 15:23:04.222905 1994072832 solver.cpp:298]     Test net output #1: loss = 0.775096 (* 1 = 0.775096 loss)
I0112 15:23:04.223547 1994072832 solver.cpp:191] Iteration 200000, loss = 0.443174
I0112 15:23:04.223562 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.833333
I0112 15:23:04.223567 1994072832 solver.cpp:206]     Train net output #1: loss = 0.443174 (* 1 = 0.443174 loss)
I0112 15:23:04.223572 1994072832 solver.cpp:403] Iteration 200000, lr = 0.00101938
I0112 15:23:22.649647 1994072832 solver.cpp:191] Iteration 210000, loss = 0.426086
I0112 15:23:22.649672 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.816667
I0112 15:23:22.649680 1994072832 solver.cpp:206]     Train net output #1: loss = 0.426086 (* 1 = 0.426086 loss)
I0112 15:23:22.649724 1994072832 solver.cpp:403] Iteration 210000, lr = 0.000984426
I0112 15:23:41.110462 1994072832 solver.cpp:191] Iteration 220000, loss = 0.409062
I0112 15:23:41.110501 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.866667
I0112 15:23:41.110508 1994072832 solver.cpp:206]     Train net output #1: loss = 0.409062 (* 1 = 0.409062 loss)
I0112 15:23:41.110513 1994072832 solver.cpp:403] Iteration 220000, lr = 0.000952147
I0112 15:23:59.509433 1994072832 solver.cpp:191] Iteration 230000, loss = 0.395425
I0112 15:23:59.509459 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.866667
I0112 15:23:59.509467 1994072832 solver.cpp:206]     Train net output #1: loss = 0.395425 (* 1 = 0.395425 loss)
I0112 15:23:59.509508 1994072832 solver.cpp:403] Iteration 230000, lr = 0.000922235
I0112 15:24:17.917023 1994072832 solver.cpp:191] Iteration 240000, loss = 0.385255
I0112 15:24:17.917062 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.883333
I0112 15:24:17.917074 1994072832 solver.cpp:206]     Train net output #1: loss = 0.385255 (* 1 = 0.385255 loss)
I0112 15:24:17.917080 1994072832 solver.cpp:403] Iteration 240000, lr = 0.000894427
I0112 15:24:36.302918 1994072832 solver.cpp:191] Iteration 250000, loss = 0.370448
I0112 15:24:36.302944 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.883333
I0112 15:24:36.302952 1994072832 solver.cpp:206]     Train net output #1: loss = 0.370448 (* 1 = 0.370448 loss)
I0112 15:24:36.302956 1994072832 solver.cpp:403] Iteration 250000, lr = 0.0008685
I0112 15:24:54.786253 1994072832 solver.cpp:191] Iteration 260000, loss = 0.356975
I0112 15:24:54.786289 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.883333
I0112 15:24:54.786298 1994072832 solver.cpp:206]     Train net output #1: loss = 0.356975 (* 1 = 0.356975 loss)
I0112 15:24:54.786345 1994072832 solver.cpp:403] Iteration 260000, lr = 0.000844262
I0112 15:25:13.250880 1994072832 solver.cpp:191] Iteration 270000, loss = 0.346911
I0112 15:25:13.250906 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.933333
I0112 15:25:13.250913 1994072832 solver.cpp:206]     Train net output #1: loss = 0.346911 (* 1 = 0.346911 loss)
I0112 15:25:13.250918 1994072832 solver.cpp:403] Iteration 270000, lr = 0.000821545
I0112 15:25:31.679658 1994072832 solver.cpp:191] Iteration 280000, loss = 0.341772
I0112 15:25:31.679697 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.916667
I0112 15:25:31.679704 1994072832 solver.cpp:206]     Train net output #1: loss = 0.341772 (* 1 = 0.341772 loss)
I0112 15:25:31.679709 1994072832 solver.cpp:403] Iteration 280000, lr = 0.000800205
I0112 15:25:50.122391 1994072832 solver.cpp:191] Iteration 290000, loss = 0.334126
I0112 15:25:50.122416 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.933333
I0112 15:25:50.122424 1994072832 solver.cpp:206]     Train net output #1: loss = 0.334126 (* 1 = 0.334126 loss)
I0112 15:25:50.122429 1994072832 solver.cpp:403] Iteration 290000, lr = 0.000780116
I0112 15:26:08.531996 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_300000.caffemodel
I0112 15:26:08.549974 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_300000.solverstate
I0112 15:26:08.559824 1994072832 solver.cpp:247] Iteration 300000, Testing net (#0)
I0112 15:26:08.622928 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7432
I0112 15:26:08.622956 1994072832 solver.cpp:298]     Test net output #1: loss = 0.775938 (* 1 = 0.775938 loss)
I0112 15:26:08.623603 1994072832 solver.cpp:191] Iteration 300000, loss = 0.327797
I0112 15:26:08.623616 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.916667
I0112 15:26:08.623623 1994072832 solver.cpp:206]     Train net output #1: loss = 0.327797 (* 1 = 0.327797 loss)
I0112 15:26:08.623628 1994072832 solver.cpp:403] Iteration 300000, lr = 0.000761165
I0112 15:26:27.024248 1994072832 solver.cpp:191] Iteration 310000, loss = 0.320268
I0112 15:26:27.024273 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.9
I0112 15:26:27.024281 1994072832 solver.cpp:206]     Train net output #1: loss = 0.320268 (* 1 = 0.320268 loss)
I0112 15:26:27.024286 1994072832 solver.cpp:403] Iteration 310000, lr = 0.000743254
I0112 15:26:45.439290 1994072832 solver.cpp:191] Iteration 320000, loss = 0.313205
I0112 15:26:45.439327 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.9
I0112 15:26:45.439335 1994072832 solver.cpp:206]     Train net output #1: loss = 0.313205 (* 1 = 0.313205 loss)
I0112 15:26:45.439371 1994072832 solver.cpp:403] Iteration 320000, lr = 0.000726297
I0112 15:27:03.822149 1994072832 solver.cpp:191] Iteration 330000, loss = 0.303579
I0112 15:27:03.822192 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.916667
I0112 15:27:03.822211 1994072832 solver.cpp:206]     Train net output #1: loss = 0.303579 (* 1 = 0.303579 loss)
I0112 15:27:03.822216 1994072832 solver.cpp:403] Iteration 330000, lr = 0.000710217
I0112 15:27:22.206660 1994072832 solver.cpp:191] Iteration 340000, loss = 0.295092
I0112 15:27:22.206696 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.933333
I0112 15:27:22.206704 1994072832 solver.cpp:206]     Train net output #1: loss = 0.295092 (* 1 = 0.295092 loss)
I0112 15:27:22.206740 1994072832 solver.cpp:403] Iteration 340000, lr = 0.000694943
I0112 15:27:40.661612 1994072832 solver.cpp:191] Iteration 350000, loss = 0.292749
I0112 15:27:40.661638 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:27:40.661645 1994072832 solver.cpp:206]     Train net output #1: loss = 0.292749 (* 1 = 0.292749 loss)
I0112 15:27:40.661650 1994072832 solver.cpp:403] Iteration 350000, lr = 0.000680414
I0112 15:27:59.104964 1994072832 solver.cpp:191] Iteration 360000, loss = 0.285809
I0112 15:27:59.105003 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:27:59.105032 1994072832 solver.cpp:206]     Train net output #1: loss = 0.285809 (* 1 = 0.285809 loss)
I0112 15:27:59.105044 1994072832 solver.cpp:403] Iteration 360000, lr = 0.000666575
I0112 15:28:17.498944 1994072832 solver.cpp:191] Iteration 370000, loss = 0.28079
I0112 15:28:17.498970 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:28:17.498977 1994072832 solver.cpp:206]     Train net output #1: loss = 0.28079 (* 1 = 0.28079 loss)
I0112 15:28:17.498983 1994072832 solver.cpp:403] Iteration 370000, lr = 0.000653375
I0112 15:28:35.912915 1994072832 solver.cpp:191] Iteration 380000, loss = 0.273424
I0112 15:28:35.912953 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:28:35.912961 1994072832 solver.cpp:206]     Train net output #1: loss = 0.273424 (* 1 = 0.273424 loss)
I0112 15:28:35.912998 1994072832 solver.cpp:403] Iteration 380000, lr = 0.000640769
I0112 15:28:54.308063 1994072832 solver.cpp:191] Iteration 390000, loss = 0.267523
I0112 15:28:54.308089 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:28:54.308096 1994072832 solver.cpp:206]     Train net output #1: loss = 0.267523 (* 1 = 0.267523 loss)
I0112 15:28:54.308101 1994072832 solver.cpp:403] Iteration 390000, lr = 0.000628717
I0112 15:29:12.814024 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_400000.caffemodel
I0112 15:29:12.835558 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_400000.solverstate
I0112 15:29:12.843798 1994072832 solver.cpp:247] Iteration 400000, Testing net (#0)
I0112 15:29:12.907054 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7394
I0112 15:29:12.907083 1994072832 solver.cpp:298]     Test net output #1: loss = 0.793603 (* 1 = 0.793603 loss)
I0112 15:29:12.907765 1994072832 solver.cpp:191] Iteration 400000, loss = 0.26152
I0112 15:29:12.907781 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:29:12.907788 1994072832 solver.cpp:206]     Train net output #1: loss = 0.26152 (* 1 = 0.26152 loss)
I0112 15:29:12.907793 1994072832 solver.cpp:403] Iteration 400000, lr = 0.00061718
I0112 15:29:31.361428 1994072832 solver.cpp:191] Iteration 410000, loss = 0.255591
I0112 15:29:31.361454 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:29:31.361461 1994072832 solver.cpp:206]     Train net output #1: loss = 0.255591 (* 1 = 0.255591 loss)
I0112 15:29:31.361466 1994072832 solver.cpp:403] Iteration 410000, lr = 0.000606126
I0112 15:29:49.841920 1994072832 solver.cpp:191] Iteration 420000, loss = 0.250278
I0112 15:29:49.841958 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:29:49.841966 1994072832 solver.cpp:206]     Train net output #1: loss = 0.250278 (* 1 = 0.250278 loss)
I0112 15:29:49.841971 1994072832 solver.cpp:403] Iteration 420000, lr = 0.000595523
I0112 15:30:08.299088 1994072832 solver.cpp:191] Iteration 430000, loss = 0.25021
I0112 15:30:08.299113 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:30:08.299121 1994072832 solver.cpp:206]     Train net output #1: loss = 0.25021 (* 1 = 0.25021 loss)
I0112 15:30:08.299126 1994072832 solver.cpp:403] Iteration 430000, lr = 0.000585343
I0112 15:30:26.715716 1994072832 solver.cpp:191] Iteration 440000, loss = 0.247372
I0112 15:30:26.715752 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:30:26.715760 1994072832 solver.cpp:206]     Train net output #1: loss = 0.247372 (* 1 = 0.247372 loss)
I0112 15:30:26.715809 1994072832 solver.cpp:403] Iteration 440000, lr = 0.00057556
I0112 15:30:45.191660 1994072832 solver.cpp:191] Iteration 450000, loss = 0.241334
I0112 15:30:45.191684 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:30:45.191691 1994072832 solver.cpp:206]     Train net output #1: loss = 0.241334 (* 1 = 0.241334 loss)
I0112 15:30:45.191696 1994072832 solver.cpp:403] Iteration 450000, lr = 0.00056615
I0112 15:31:03.605345 1994072832 solver.cpp:191] Iteration 460000, loss = 0.238101
I0112 15:31:03.605382 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:31:03.605391 1994072832 solver.cpp:206]     Train net output #1: loss = 0.238101 (* 1 = 0.238101 loss)
I0112 15:31:03.605440 1994072832 solver.cpp:403] Iteration 460000, lr = 0.000557092
I0112 15:31:22.098281 1994072832 solver.cpp:191] Iteration 470000, loss = 0.23668
I0112 15:31:22.098305 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:31:22.098314 1994072832 solver.cpp:206]     Train net output #1: loss = 0.23668 (* 1 = 0.23668 loss)
I0112 15:31:22.098317 1994072832 solver.cpp:403] Iteration 470000, lr = 0.000548364
I0112 15:31:41.029528 1994072832 solver.cpp:191] Iteration 480000, loss = 0.230649
I0112 15:31:41.037035 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:31:41.037052 1994072832 solver.cpp:206]     Train net output #1: loss = 0.230649 (* 1 = 0.230649 loss)
I0112 15:31:41.037083 1994072832 solver.cpp:403] Iteration 480000, lr = 0.000539949
I0112 15:32:00.061102 1994072832 solver.cpp:191] Iteration 490000, loss = 0.227728
I0112 15:32:00.061128 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:32:00.061136 1994072832 solver.cpp:206]     Train net output #1: loss = 0.227728 (* 1 = 0.227728 loss)
I0112 15:32:00.061141 1994072832 solver.cpp:403] Iteration 490000, lr = 0.00053183
I0112 15:32:19.030179 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_500000.caffemodel
I0112 15:32:19.051911 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_500000.solverstate
I0112 15:32:19.060189 1994072832 solver.cpp:247] Iteration 500000, Testing net (#0)
I0112 15:32:19.125105 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7372
I0112 15:32:19.125131 1994072832 solver.cpp:298]     Test net output #1: loss = 0.810423 (* 1 = 0.810423 loss)
I0112 15:32:19.125773 1994072832 solver.cpp:191] Iteration 500000, loss = 0.225385
I0112 15:32:19.125785 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:32:19.125792 1994072832 solver.cpp:206]     Train net output #1: loss = 0.225385 (* 1 = 0.225385 loss)
I0112 15:32:19.125797 1994072832 solver.cpp:403] Iteration 500000, lr = 0.000523989
I0112 15:32:37.556565 1994072832 solver.cpp:191] Iteration 510000, loss = 0.223005
I0112 15:32:37.556587 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:32:37.556596 1994072832 solver.cpp:206]     Train net output #1: loss = 0.223005 (* 1 = 0.223005 loss)
I0112 15:32:37.556599 1994072832 solver.cpp:403] Iteration 510000, lr = 0.000516413
I0112 15:32:55.941443 1994072832 solver.cpp:191] Iteration 520000, loss = 0.220748
I0112 15:32:55.941480 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:32:55.941489 1994072832 solver.cpp:206]     Train net output #1: loss = 0.220748 (* 1 = 0.220748 loss)
I0112 15:32:55.941525 1994072832 solver.cpp:403] Iteration 520000, lr = 0.000509088
I0112 15:33:14.627898 1994072832 solver.cpp:191] Iteration 530000, loss = 0.217749
I0112 15:33:14.627923 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:33:14.627933 1994072832 solver.cpp:206]     Train net output #1: loss = 0.217749 (* 1 = 0.217749 loss)
I0112 15:33:14.627995 1994072832 solver.cpp:403] Iteration 530000, lr = 0.000502001
I0112 15:33:33.464964 1994072832 solver.cpp:191] Iteration 540000, loss = 0.215924
I0112 15:33:33.465003 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:33:33.465011 1994072832 solver.cpp:206]     Train net output #1: loss = 0.215924 (* 1 = 0.215924 loss)
I0112 15:33:33.465015 1994072832 solver.cpp:403] Iteration 540000, lr = 0.00049514
I0112 15:33:52.117261 1994072832 solver.cpp:191] Iteration 550000, loss = 0.212336
I0112 15:33:52.117287 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:33:52.117295 1994072832 solver.cpp:206]     Train net output #1: loss = 0.212336 (* 1 = 0.212336 loss)
I0112 15:33:52.117300 1994072832 solver.cpp:403] Iteration 550000, lr = 0.000488494
I0112 15:34:10.606899 1994072832 solver.cpp:191] Iteration 560000, loss = 0.208971
I0112 15:34:10.606937 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:34:10.606946 1994072832 solver.cpp:206]     Train net output #1: loss = 0.208971 (* 1 = 0.208971 loss)
I0112 15:34:10.606993 1994072832 solver.cpp:403] Iteration 560000, lr = 0.000482052
I0112 15:34:28.990391 1994072832 solver.cpp:191] Iteration 570000, loss = 0.206185
I0112 15:34:28.990417 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:34:28.990425 1994072832 solver.cpp:206]     Train net output #1: loss = 0.206185 (* 1 = 0.206185 loss)
I0112 15:34:28.990430 1994072832 solver.cpp:403] Iteration 570000, lr = 0.000475805
I0112 15:34:47.514879 1994072832 solver.cpp:191] Iteration 580000, loss = 0.207556
I0112 15:34:47.515630 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:34:47.515641 1994072832 solver.cpp:206]     Train net output #1: loss = 0.207556 (* 1 = 0.207556 loss)
I0112 15:34:47.515647 1994072832 solver.cpp:403] Iteration 580000, lr = 0.000469744
I0112 15:35:05.935045 1994072832 solver.cpp:191] Iteration 590000, loss = 0.204865
I0112 15:35:05.935070 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:35:05.935077 1994072832 solver.cpp:206]     Train net output #1: loss = 0.204865 (* 1 = 0.204865 loss)
I0112 15:35:05.935082 1994072832 solver.cpp:403] Iteration 590000, lr = 0.00046386
I0112 15:35:24.428853 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_600000.caffemodel
I0112 15:35:24.444885 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_600000.solverstate
I0112 15:35:24.457927 1994072832 solver.cpp:247] Iteration 600000, Testing net (#0)
I0112 15:35:24.570933 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.735
I0112 15:35:24.570960 1994072832 solver.cpp:298]     Test net output #1: loss = 0.82058 (* 1 = 0.82058 loss)
I0112 15:35:24.571684 1994072832 solver.cpp:191] Iteration 600000, loss = 0.203181
I0112 15:35:24.571699 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:35:24.571707 1994072832 solver.cpp:206]     Train net output #1: loss = 0.203181 (* 1 = 0.203181 loss)
I0112 15:35:24.571712 1994072832 solver.cpp:403] Iteration 600000, lr = 0.000458145
I0112 15:35:43.030194 1994072832 solver.cpp:191] Iteration 610000, loss = 0.200995
I0112 15:35:43.030216 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:35:43.030225 1994072832 solver.cpp:206]     Train net output #1: loss = 0.200995 (* 1 = 0.200995 loss)
I0112 15:35:43.030230 1994072832 solver.cpp:403] Iteration 610000, lr = 0.000452591
I0112 15:36:01.416116 1994072832 solver.cpp:191] Iteration 620000, loss = 0.201963
I0112 15:36:01.416154 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:36:01.416162 1994072832 solver.cpp:206]     Train net output #1: loss = 0.201963 (* 1 = 0.201963 loss)
I0112 15:36:01.416167 1994072832 solver.cpp:403] Iteration 620000, lr = 0.000447193
I0112 15:36:19.994768 1994072832 solver.cpp:191] Iteration 630000, loss = 0.199832
I0112 15:36:19.994793 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:36:19.994801 1994072832 solver.cpp:206]     Train net output #1: loss = 0.199832 (* 1 = 0.199832 loss)
I0112 15:36:19.994806 1994072832 solver.cpp:403] Iteration 630000, lr = 0.000441942
I0112 15:36:38.526320 1994072832 solver.cpp:191] Iteration 640000, loss = 0.201211
I0112 15:36:38.526355 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:36:38.526363 1994072832 solver.cpp:206]     Train net output #1: loss = 0.201211 (* 1 = 0.201211 loss)
I0112 15:36:38.526377 1994072832 solver.cpp:403] Iteration 640000, lr = 0.000436833
I0112 15:36:57.186162 1994072832 solver.cpp:191] Iteration 650000, loss = 0.197203
I0112 15:36:57.186190 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:36:57.186199 1994072832 solver.cpp:206]     Train net output #1: loss = 0.197203 (* 1 = 0.197203 loss)
I0112 15:36:57.186205 1994072832 solver.cpp:403] Iteration 650000, lr = 0.000431859
I0112 15:37:16.145139 1994072832 solver.cpp:191] Iteration 660000, loss = 0.195989
I0112 15:37:16.145176 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:37:16.145184 1994072832 solver.cpp:206]     Train net output #1: loss = 0.195989 (* 1 = 0.195989 loss)
I0112 15:37:16.145197 1994072832 solver.cpp:403] Iteration 660000, lr = 0.000427016
I0112 15:37:34.736376 1994072832 solver.cpp:191] Iteration 670000, loss = 0.197003
I0112 15:37:34.736399 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:37:34.736407 1994072832 solver.cpp:206]     Train net output #1: loss = 0.197003 (* 1 = 0.197003 loss)
I0112 15:37:34.736412 1994072832 solver.cpp:403] Iteration 670000, lr = 0.000422297
I0112 15:37:53.256888 1994072832 solver.cpp:191] Iteration 680000, loss = 0.197194
I0112 15:37:53.257535 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:37:53.257546 1994072832 solver.cpp:206]     Train net output #1: loss = 0.197194 (* 1 = 0.197194 loss)
I0112 15:37:53.257551 1994072832 solver.cpp:403] Iteration 680000, lr = 0.000417699
I0112 15:38:11.913060 1994072832 solver.cpp:191] Iteration 690000, loss = 0.194467
I0112 15:38:11.913105 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:38:11.913120 1994072832 solver.cpp:206]     Train net output #1: loss = 0.194467 (* 1 = 0.194467 loss)
I0112 15:38:11.913125 1994072832 solver.cpp:403] Iteration 690000, lr = 0.000413215
I0112 15:38:32.430935 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_700000.caffemodel
I0112 15:38:32.449053 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_700000.solverstate
I0112 15:38:32.458690 1994072832 solver.cpp:247] Iteration 700000, Testing net (#0)
I0112 15:38:32.525005 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7361
I0112 15:38:32.525032 1994072832 solver.cpp:298]     Test net output #1: loss = 0.828125 (* 1 = 0.828125 loss)
I0112 15:38:32.525673 1994072832 solver.cpp:191] Iteration 700000, loss = 0.19331
I0112 15:38:32.525686 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:38:32.525692 1994072832 solver.cpp:206]     Train net output #1: loss = 0.19331 (* 1 = 0.19331 loss)
I0112 15:38:32.525697 1994072832 solver.cpp:403] Iteration 700000, lr = 0.000408843
I0112 15:38:51.167258 1994072832 solver.cpp:191] Iteration 710000, loss = 0.193923
I0112 15:38:51.167282 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:38:51.167290 1994072832 solver.cpp:206]     Train net output #1: loss = 0.193923 (* 1 = 0.193923 loss)
I0112 15:38:51.167304 1994072832 solver.cpp:403] Iteration 710000, lr = 0.000404576
I0112 15:39:09.749018 1994072832 solver.cpp:191] Iteration 720000, loss = 0.193582
I0112 15:39:09.749057 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:39:09.749064 1994072832 solver.cpp:206]     Train net output #1: loss = 0.193582 (* 1 = 0.193582 loss)
I0112 15:39:09.749076 1994072832 solver.cpp:403] Iteration 720000, lr = 0.000400413
I0112 15:39:28.333505 1994072832 solver.cpp:191] Iteration 730000, loss = 0.193971
I0112 15:39:28.333531 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:39:28.333539 1994072832 solver.cpp:206]     Train net output #1: loss = 0.193971 (* 1 = 0.193971 loss)
I0112 15:39:28.333592 1994072832 solver.cpp:403] Iteration 730000, lr = 0.000396348
I0112 15:39:46.774364 1994072832 solver.cpp:191] Iteration 740000, loss = 0.19444
I0112 15:39:46.774401 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:39:46.774410 1994072832 solver.cpp:206]     Train net output #1: loss = 0.19444 (* 1 = 0.19444 loss)
I0112 15:39:46.774458 1994072832 solver.cpp:403] Iteration 740000, lr = 0.000392377
I0112 15:40:05.225025 1994072832 solver.cpp:191] Iteration 750000, loss = 0.193932
I0112 15:40:05.225050 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:40:05.225059 1994072832 solver.cpp:206]     Train net output #1: loss = 0.193932 (* 1 = 0.193932 loss)
I0112 15:40:05.225100 1994072832 solver.cpp:403] Iteration 750000, lr = 0.000388499
I0112 15:40:23.666749 1994072832 solver.cpp:191] Iteration 760000, loss = 0.19572
I0112 15:40:23.666789 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:40:23.666797 1994072832 solver.cpp:206]     Train net output #1: loss = 0.19572 (* 1 = 0.19572 loss)
I0112 15:40:23.666844 1994072832 solver.cpp:403] Iteration 760000, lr = 0.000384709
I0112 15:40:42.111731 1994072832 solver.cpp:191] Iteration 770000, loss = 0.195601
I0112 15:40:42.111755 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:40:42.111763 1994072832 solver.cpp:206]     Train net output #1: loss = 0.195601 (* 1 = 0.195601 loss)
I0112 15:40:42.111768 1994072832 solver.cpp:403] Iteration 770000, lr = 0.000381004
I0112 15:41:00.680467 1994072832 solver.cpp:191] Iteration 780000, loss = 0.198846
I0112 15:41:00.680521 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:41:00.680529 1994072832 solver.cpp:206]     Train net output #1: loss = 0.198846 (* 1 = 0.198846 loss)
I0112 15:41:00.680534 1994072832 solver.cpp:403] Iteration 780000, lr = 0.000377381
I0112 15:41:19.316478 1994072832 solver.cpp:191] Iteration 790000, loss = 0.198399
I0112 15:41:19.316505 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:41:19.316514 1994072832 solver.cpp:206]     Train net output #1: loss = 0.198399 (* 1 = 0.198399 loss)
I0112 15:41:19.316519 1994072832 solver.cpp:403] Iteration 790000, lr = 0.000373837
I0112 15:41:38.003262 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_800000.caffemodel
I0112 15:41:38.022939 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_800000.solverstate
I0112 15:41:38.031779 1994072832 solver.cpp:247] Iteration 800000, Testing net (#0)
I0112 15:41:38.095443 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7383
I0112 15:41:38.095471 1994072832 solver.cpp:298]     Test net output #1: loss = 0.833814 (* 1 = 0.833814 loss)
I0112 15:41:38.096113 1994072832 solver.cpp:191] Iteration 800000, loss = 0.198838
I0112 15:41:38.096127 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:41:38.096134 1994072832 solver.cpp:206]     Train net output #1: loss = 0.198838 (* 1 = 0.198838 loss)
I0112 15:41:38.096139 1994072832 solver.cpp:403] Iteration 800000, lr = 0.00037037
I0112 15:41:56.634624 1994072832 solver.cpp:191] Iteration 810000, loss = 0.202648
I0112 15:41:56.634650 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:41:56.634657 1994072832 solver.cpp:206]     Train net output #1: loss = 0.202648 (* 1 = 0.202648 loss)
I0112 15:41:56.634662 1994072832 solver.cpp:403] Iteration 810000, lr = 0.000366978
I0112 15:42:15.135318 1994072832 solver.cpp:191] Iteration 820000, loss = 0.202667
I0112 15:42:15.135356 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:42:15.135365 1994072832 solver.cpp:206]     Train net output #1: loss = 0.202667 (* 1 = 0.202667 loss)
I0112 15:42:15.135401 1994072832 solver.cpp:403] Iteration 820000, lr = 0.000363657
I0112 15:42:33.689463 1994072832 solver.cpp:191] Iteration 830000, loss = 0.201878
I0112 15:42:33.689491 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:42:33.689497 1994072832 solver.cpp:206]     Train net output #1: loss = 0.201878 (* 1 = 0.201878 loss)
I0112 15:42:33.689502 1994072832 solver.cpp:403] Iteration 830000, lr = 0.000360405
I0112 15:42:52.373199 1994072832 solver.cpp:191] Iteration 840000, loss = 0.200808
I0112 15:42:52.373237 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:42:52.373245 1994072832 solver.cpp:206]     Train net output #1: loss = 0.200808 (* 1 = 0.200808 loss)
I0112 15:42:52.373250 1994072832 solver.cpp:403] Iteration 840000, lr = 0.00035722
I0112 15:43:11.160917 1994072832 solver.cpp:191] Iteration 850000, loss = 0.200612
I0112 15:43:11.160941 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:43:11.160949 1994072832 solver.cpp:206]     Train net output #1: loss = 0.200612 (* 1 = 0.200612 loss)
I0112 15:43:11.160954 1994072832 solver.cpp:403] Iteration 850000, lr = 0.0003541
I0112 15:43:29.970487 1994072832 solver.cpp:191] Iteration 860000, loss = 0.197596
I0112 15:43:29.970527 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:43:29.970535 1994072832 solver.cpp:206]     Train net output #1: loss = 0.197596 (* 1 = 0.197596 loss)
I0112 15:43:29.970541 1994072832 solver.cpp:403] Iteration 860000, lr = 0.000351043
I0112 15:43:48.718181 1994072832 solver.cpp:191] Iteration 870000, loss = 0.195839
I0112 15:43:48.718209 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:43:48.718215 1994072832 solver.cpp:206]     Train net output #1: loss = 0.195839 (* 1 = 0.195839 loss)
I0112 15:43:48.718220 1994072832 solver.cpp:403] Iteration 870000, lr = 0.000348047
I0112 15:44:07.415853 1994072832 solver.cpp:191] Iteration 880000, loss = 0.194663
I0112 15:44:07.415906 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:44:07.415915 1994072832 solver.cpp:206]     Train net output #1: loss = 0.194663 (* 1 = 0.194663 loss)
I0112 15:44:07.415964 1994072832 solver.cpp:403] Iteration 880000, lr = 0.00034511
I0112 15:44:26.255072 1994072832 solver.cpp:191] Iteration 890000, loss = 0.193658
I0112 15:44:26.255096 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.95
I0112 15:44:26.255105 1994072832 solver.cpp:206]     Train net output #1: loss = 0.193658 (* 1 = 0.193658 loss)
I0112 15:44:26.255110 1994072832 solver.cpp:403] Iteration 890000, lr = 0.00034223
I0112 15:44:44.902184 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_900000.caffemodel
I0112 15:44:44.920624 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_900000.solverstate
I0112 15:44:44.928807 1994072832 solver.cpp:247] Iteration 900000, Testing net (#0)
I0112 15:44:44.992241 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7346
I0112 15:44:44.992267 1994072832 solver.cpp:298]     Test net output #1: loss = 0.849112 (* 1 = 0.849112 loss)
I0112 15:44:44.992929 1994072832 solver.cpp:191] Iteration 900000, loss = 0.192657
I0112 15:44:44.992945 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:44:44.992954 1994072832 solver.cpp:206]     Train net output #1: loss = 0.192657 (* 1 = 0.192657 loss)
I0112 15:44:44.992959 1994072832 solver.cpp:403] Iteration 900000, lr = 0.000339406
I0112 15:45:03.775311 1994072832 solver.cpp:191] Iteration 910000, loss = 0.188574
I0112 15:45:03.775336 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:45:03.775344 1994072832 solver.cpp:206]     Train net output #1: loss = 0.188574 (* 1 = 0.188574 loss)
I0112 15:45:03.775349 1994072832 solver.cpp:403] Iteration 910000, lr = 0.000336635
I0112 15:45:22.619290 1994072832 solver.cpp:191] Iteration 920000, loss = 0.186897
I0112 15:45:22.619328 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:45:22.619338 1994072832 solver.cpp:206]     Train net output #1: loss = 0.186897 (* 1 = 0.186897 loss)
I0112 15:45:22.619343 1994072832 solver.cpp:403] Iteration 920000, lr = 0.000333916
I0112 15:45:41.913424 1994072832 solver.cpp:191] Iteration 930000, loss = 0.185587
I0112 15:45:41.913453 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:45:41.913465 1994072832 solver.cpp:206]     Train net output #1: loss = 0.185587 (* 1 = 0.185587 loss)
I0112 15:45:41.913470 1994072832 solver.cpp:403] Iteration 930000, lr = 0.000331249
I0112 15:46:01.043395 1994072832 solver.cpp:191] Iteration 940000, loss = 0.182907
I0112 15:46:01.043431 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.966667
I0112 15:46:01.043439 1994072832 solver.cpp:206]     Train net output #1: loss = 0.182907 (* 1 = 0.182907 loss)
I0112 15:46:01.043444 1994072832 solver.cpp:403] Iteration 940000, lr = 0.00032863
I0112 15:46:19.910630 1994072832 solver.cpp:191] Iteration 950000, loss = 0.180828
I0112 15:46:19.910660 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:46:19.910668 1994072832 solver.cpp:206]     Train net output #1: loss = 0.180828 (* 1 = 0.180828 loss)
I0112 15:46:19.910722 1994072832 solver.cpp:403] Iteration 950000, lr = 0.000326059
I0112 15:46:38.959074 1994072832 solver.cpp:191] Iteration 960000, loss = 0.178785
I0112 15:46:38.959110 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:46:38.959120 1994072832 solver.cpp:206]     Train net output #1: loss = 0.178785 (* 1 = 0.178785 loss)
I0112 15:46:38.959132 1994072832 solver.cpp:403] Iteration 960000, lr = 0.000323535
I0112 15:46:57.627866 1994072832 solver.cpp:191] Iteration 970000, loss = 0.177323
I0112 15:46:57.627890 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:46:57.627898 1994072832 solver.cpp:206]     Train net output #1: loss = 0.177323 (* 1 = 0.177323 loss)
I0112 15:46:57.627903 1994072832 solver.cpp:403] Iteration 970000, lr = 0.000321056
I0112 15:47:16.235277 1994072832 solver.cpp:191] Iteration 980000, loss = 0.175492
I0112 15:47:16.235330 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:47:16.235339 1994072832 solver.cpp:206]     Train net output #1: loss = 0.175492 (* 1 = 0.175492 loss)
I0112 15:47:16.235376 1994072832 solver.cpp:403] Iteration 980000, lr = 0.00031862
I0112 15:47:34.664198 1994072832 solver.cpp:191] Iteration 990000, loss = 0.172538
I0112 15:47:34.664223 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:47:34.664232 1994072832 solver.cpp:206]     Train net output #1: loss = 0.172538 (* 1 = 0.172538 loss)
I0112 15:47:34.664244 1994072832 solver.cpp:403] Iteration 990000, lr = 0.000316228
I0112 15:47:53.273049 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_1000000.caffemodel
I0112 15:47:53.294507 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_1000000.solverstate
I0112 15:47:53.302983 1994072832 solver.cpp:247] Iteration 1000000, Testing net (#0)
I0112 15:47:53.366731 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7376
I0112 15:47:53.366760 1994072832 solver.cpp:298]     Test net output #1: loss = 0.842924 (* 1 = 0.842924 loss)
I0112 15:47:53.367429 1994072832 solver.cpp:191] Iteration 1000000, loss = 0.170882
I0112 15:47:53.367445 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:47:53.367454 1994072832 solver.cpp:206]     Train net output #1: loss = 0.170882 (* 1 = 0.170882 loss)
I0112 15:47:53.367458 1994072832 solver.cpp:403] Iteration 1000000, lr = 0.000313877
I0112 15:48:12.090229 1994072832 solver.cpp:191] Iteration 1010000, loss = 0.169335
I0112 15:48:12.090255 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:48:12.090261 1994072832 solver.cpp:206]     Train net output #1: loss = 0.169335 (* 1 = 0.169335 loss)
I0112 15:48:12.090266 1994072832 solver.cpp:403] Iteration 1010000, lr = 0.000311566
I0112 15:48:30.967067 1994072832 solver.cpp:191] Iteration 1020000, loss = 0.167023
I0112 15:48:30.967103 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:48:30.967113 1994072832 solver.cpp:206]     Train net output #1: loss = 0.167023 (* 1 = 0.167023 loss)
I0112 15:48:30.967159 1994072832 solver.cpp:403] Iteration 1020000, lr = 0.000309294
I0112 15:48:49.865674 1994072832 solver.cpp:191] Iteration 1030000, loss = 0.166563
I0112 15:48:49.865699 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:48:49.865706 1994072832 solver.cpp:206]     Train net output #1: loss = 0.166563 (* 1 = 0.166563 loss)
I0112 15:48:49.865711 1994072832 solver.cpp:403] Iteration 1030000, lr = 0.000307061
I0112 15:49:08.780071 1994072832 solver.cpp:191] Iteration 1040000, loss = 0.164777
I0112 15:49:08.780108 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:49:08.780117 1994072832 solver.cpp:206]     Train net output #1: loss = 0.164777 (* 1 = 0.164777 loss)
I0112 15:49:08.780165 1994072832 solver.cpp:403] Iteration 1040000, lr = 0.000304865
I0112 15:49:29.861907 1994072832 solver.cpp:191] Iteration 1050000, loss = 0.163113
I0112 15:49:29.862013 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:49:29.862030 1994072832 solver.cpp:206]     Train net output #1: loss = 0.163113 (* 1 = 0.163113 loss)
I0112 15:49:29.862035 1994072832 solver.cpp:403] Iteration 1050000, lr = 0.000302706
I0112 15:49:53.029171 1994072832 solver.cpp:191] Iteration 1060000, loss = 0.161702
I0112 15:49:53.029208 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:49:53.029217 1994072832 solver.cpp:206]     Train net output #1: loss = 0.161702 (* 1 = 0.161702 loss)
I0112 15:49:53.029222 1994072832 solver.cpp:403] Iteration 1060000, lr = 0.000300581
I0112 15:50:12.490458 1994072832 solver.cpp:191] Iteration 1070000, loss = 0.16124
I0112 15:50:12.490483 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:50:12.490489 1994072832 solver.cpp:206]     Train net output #1: loss = 0.16124 (* 1 = 0.16124 loss)
I0112 15:50:12.490495 1994072832 solver.cpp:403] Iteration 1070000, lr = 0.000298492
I0112 15:50:32.090328 1994072832 solver.cpp:191] Iteration 1080000, loss = 0.159417
I0112 15:50:32.090386 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:50:32.090396 1994072832 solver.cpp:206]     Train net output #1: loss = 0.159417 (* 1 = 0.159417 loss)
I0112 15:50:32.090402 1994072832 solver.cpp:403] Iteration 1080000, lr = 0.000296435
I0112 15:50:51.792732 1994072832 solver.cpp:191] Iteration 1090000, loss = 0.157255
I0112 15:50:51.792758 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:50:51.792765 1994072832 solver.cpp:206]     Train net output #1: loss = 0.157255 (* 1 = 0.157255 loss)
I0112 15:50:51.792770 1994072832 solver.cpp:403] Iteration 1090000, lr = 0.000294412
I0112 15:51:11.206817 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_1100000.caffemodel
I0112 15:51:11.224858 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_1100000.solverstate
I0112 15:51:11.233485 1994072832 solver.cpp:247] Iteration 1100000, Testing net (#0)
I0112 15:51:11.298969 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7391
I0112 15:51:11.298995 1994072832 solver.cpp:298]     Test net output #1: loss = 0.840216 (* 1 = 0.840216 loss)
I0112 15:51:11.299640 1994072832 solver.cpp:191] Iteration 1100000, loss = 0.157151
I0112 15:51:11.299653 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:51:11.299659 1994072832 solver.cpp:206]     Train net output #1: loss = 0.157151 (* 1 = 0.157151 loss)
I0112 15:51:11.299669 1994072832 solver.cpp:403] Iteration 1100000, lr = 0.00029242
I0112 15:51:31.007078 1994072832 solver.cpp:191] Iteration 1110000, loss = 0.155234
I0112 15:51:31.007104 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:51:31.007112 1994072832 solver.cpp:206]     Train net output #1: loss = 0.155234 (* 1 = 0.155234 loss)
I0112 15:51:31.007117 1994072832 solver.cpp:403] Iteration 1110000, lr = 0.00029046
I0112 15:51:54.441956 1994072832 solver.cpp:191] Iteration 1120000, loss = 0.15461
I0112 15:51:54.441995 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:51:54.442004 1994072832 solver.cpp:206]     Train net output #1: loss = 0.15461 (* 1 = 0.15461 loss)
I0112 15:51:54.442054 1994072832 solver.cpp:403] Iteration 1120000, lr = 0.00028853
I0112 15:52:14.496480 1994072832 solver.cpp:191] Iteration 1130000, loss = 0.153522
I0112 15:52:14.496505 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:52:14.496512 1994072832 solver.cpp:206]     Train net output #1: loss = 0.153522 (* 1 = 0.153522 loss)
I0112 15:52:14.496517 1994072832 solver.cpp:403] Iteration 1130000, lr = 0.00028663
I0112 15:52:34.858531 1994072832 solver.cpp:191] Iteration 1140000, loss = 0.152202
I0112 15:52:34.858569 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:52:34.858577 1994072832 solver.cpp:206]     Train net output #1: loss = 0.152202 (* 1 = 0.152202 loss)
I0112 15:52:34.858582 1994072832 solver.cpp:403] Iteration 1140000, lr = 0.000284758
I0112 15:52:55.164412 1994072832 solver.cpp:191] Iteration 1150000, loss = 0.151202
I0112 15:52:55.164438 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:52:55.164446 1994072832 solver.cpp:206]     Train net output #1: loss = 0.151202 (* 1 = 0.151202 loss)
I0112 15:52:55.164453 1994072832 solver.cpp:403] Iteration 1150000, lr = 0.000282915
I0112 15:53:15.324148 1994072832 solver.cpp:191] Iteration 1160000, loss = 0.150715
I0112 15:53:15.324806 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:53:15.324817 1994072832 solver.cpp:206]     Train net output #1: loss = 0.150715 (* 1 = 0.150715 loss)
I0112 15:53:15.324823 1994072832 solver.cpp:403] Iteration 1160000, lr = 0.0002811
I0112 15:53:36.016964 1994072832 solver.cpp:191] Iteration 1170000, loss = 0.150741
I0112 15:53:36.016990 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:53:36.016998 1994072832 solver.cpp:206]     Train net output #1: loss = 0.150741 (* 1 = 0.150741 loss)
I0112 15:53:36.017002 1994072832 solver.cpp:403] Iteration 1170000, lr = 0.000279311
I0112 15:53:56.476258 1994072832 solver.cpp:191] Iteration 1180000, loss = 0.148904
I0112 15:53:56.476500 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:53:56.476546 1994072832 solver.cpp:206]     Train net output #1: loss = 0.148904 (* 1 = 0.148904 loss)
I0112 15:53:56.476598 1994072832 solver.cpp:403] Iteration 1180000, lr = 0.000277549
I0112 15:54:16.634802 1994072832 solver.cpp:191] Iteration 1190000, loss = 0.148511
I0112 15:54:16.634829 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:54:16.634836 1994072832 solver.cpp:206]     Train net output #1: loss = 0.148511 (* 1 = 0.148511 loss)
I0112 15:54:16.634841 1994072832 solver.cpp:403] Iteration 1190000, lr = 0.000275813
I0112 15:54:36.713199 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_1200000.caffemodel
I0112 15:54:36.732270 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_1200000.solverstate
I0112 15:54:36.740898 1994072832 solver.cpp:247] Iteration 1200000, Testing net (#0)
I0112 15:54:36.807173 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7377
I0112 15:54:36.807201 1994072832 solver.cpp:298]     Test net output #1: loss = 0.835789 (* 1 = 0.835789 loss)
I0112 15:54:36.807849 1994072832 solver.cpp:191] Iteration 1200000, loss = 0.147612
I0112 15:54:36.807862 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:54:36.807869 1994072832 solver.cpp:206]     Train net output #1: loss = 0.147612 (* 1 = 0.147612 loss)
I0112 15:54:36.807878 1994072832 solver.cpp:403] Iteration 1200000, lr = 0.000274101
I0112 15:54:57.104408 1994072832 solver.cpp:191] Iteration 1210000, loss = 0.147094
I0112 15:54:57.104434 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:54:57.104441 1994072832 solver.cpp:206]     Train net output #1: loss = 0.147094 (* 1 = 0.147094 loss)
I0112 15:54:57.104446 1994072832 solver.cpp:403] Iteration 1210000, lr = 0.000272414
I0112 15:55:17.297366 1994072832 solver.cpp:191] Iteration 1220000, loss = 0.147192
I0112 15:55:17.297405 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:55:17.297413 1994072832 solver.cpp:206]     Train net output #1: loss = 0.147192 (* 1 = 0.147192 loss)
I0112 15:55:17.297420 1994072832 solver.cpp:403] Iteration 1220000, lr = 0.000270752
I0112 15:55:37.367872 1994072832 solver.cpp:191] Iteration 1230000, loss = 0.147195
I0112 15:55:37.367898 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:55:37.367907 1994072832 solver.cpp:206]     Train net output #1: loss = 0.147195 (* 1 = 0.147195 loss)
I0112 15:55:37.367912 1994072832 solver.cpp:403] Iteration 1230000, lr = 0.000269112
I0112 15:55:57.423478 1994072832 solver.cpp:191] Iteration 1240000, loss = 0.145709
I0112 15:55:57.423516 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:55:57.423524 1994072832 solver.cpp:206]     Train net output #1: loss = 0.145709 (* 1 = 0.145709 loss)
I0112 15:55:57.423573 1994072832 solver.cpp:403] Iteration 1240000, lr = 0.000267496
I0112 15:56:17.691776 1994072832 solver.cpp:191] Iteration 1250000, loss = 0.144913
I0112 15:56:17.691800 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:56:17.691808 1994072832 solver.cpp:206]     Train net output #1: loss = 0.144913 (* 1 = 0.144913 loss)
I0112 15:56:17.691813 1994072832 solver.cpp:403] Iteration 1250000, lr = 0.000265902
I0112 15:56:37.967082 1994072832 solver.cpp:191] Iteration 1260000, loss = 0.144289
I0112 15:56:37.967133 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:56:37.967142 1994072832 solver.cpp:206]     Train net output #1: loss = 0.144289 (* 1 = 0.144289 loss)
I0112 15:56:37.967149 1994072832 solver.cpp:403] Iteration 1260000, lr = 0.00026433
I0112 15:56:58.363631 1994072832 solver.cpp:191] Iteration 1270000, loss = 0.143955
I0112 15:56:58.363656 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:56:58.363663 1994072832 solver.cpp:206]     Train net output #1: loss = 0.143955 (* 1 = 0.143955 loss)
I0112 15:56:58.363668 1994072832 solver.cpp:403] Iteration 1270000, lr = 0.00026278
I0112 15:57:18.586136 1994072832 solver.cpp:191] Iteration 1280000, loss = 0.144074
I0112 15:57:18.586174 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:57:18.586182 1994072832 solver.cpp:206]     Train net output #1: loss = 0.144074 (* 1 = 0.144074 loss)
I0112 15:57:18.586225 1994072832 solver.cpp:403] Iteration 1280000, lr = 0.000261251
I0112 15:57:38.963049 1994072832 solver.cpp:191] Iteration 1290000, loss = 0.142805
I0112 15:57:38.963074 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:57:38.963083 1994072832 solver.cpp:206]     Train net output #1: loss = 0.142805 (* 1 = 0.142805 loss)
I0112 15:57:38.963088 1994072832 solver.cpp:403] Iteration 1290000, lr = 0.000259742
I0112 15:57:59.147771 1994072832 solver.cpp:317] Snapshotting to .49s1rzwmj_iter_1300000.caffemodel
I0112 15:57:59.166239 1994072832 solver.cpp:324] Snapshotting solver state to .49s1rzwmj_iter_1300000.solverstate
I0112 15:57:59.174412 1994072832 solver.cpp:247] Iteration 1300000, Testing net (#0)
I0112 15:57:59.241775 1994072832 solver.cpp:298]     Test net output #0: accuracy = 0.7383
I0112 15:57:59.241803 1994072832 solver.cpp:298]     Test net output #1: loss = 0.836622 (* 1 = 0.836622 loss)
I0112 15:57:59.242465 1994072832 solver.cpp:191] Iteration 1300000, loss = 0.141881
I0112 15:57:59.242480 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:57:59.242486 1994072832 solver.cpp:206]     Train net output #1: loss = 0.141881 (* 1 = 0.141881 loss)
I0112 15:57:59.242491 1994072832 solver.cpp:403] Iteration 1300000, lr = 0.000258254
I0112 15:58:19.687866 1994072832 solver.cpp:191] Iteration 1310000, loss = 0.141896
I0112 15:58:19.687917 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:58:19.687954 1994072832 solver.cpp:206]     Train net output #1: loss = 0.141896 (* 1 = 0.141896 loss)
I0112 15:58:19.687968 1994072832 solver.cpp:403] Iteration 1310000, lr = 0.000256785
I0112 15:58:39.857785 1994072832 solver.cpp:191] Iteration 1320000, loss = 0.141212
I0112 15:58:39.857831 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:58:39.857841 1994072832 solver.cpp:206]     Train net output #1: loss = 0.141212 (* 1 = 0.141212 loss)
I0112 15:58:39.857844 1994072832 solver.cpp:403] Iteration 1320000, lr = 0.000255336
I0112 15:59:00.035661 1994072832 solver.cpp:191] Iteration 1330000, loss = 0.140991
I0112 15:59:00.035688 1994072832 solver.cpp:206]     Train net output #0: accuracy = 0.983333
I0112 15:59:00.035696 1994072832 solver.cpp:206]     Train net output #1: loss = 0.140991 (* 1 = 0.140991 loss)
I0112 15:59:00.035701 1994072832 solver.cpp:403] Iteration 1330000, lr = 0.000253905
